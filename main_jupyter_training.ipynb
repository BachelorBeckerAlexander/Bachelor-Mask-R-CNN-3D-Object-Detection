{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffca9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1559edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transferLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5e4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Root directory of the project\n",
    "\n",
    "ROOT_DIR = \"C:\\\\Users\\\\Nutzer\\\\anaconda3\\\\envs\\\\myenv\\\\Mask_RCNN (works)\"\n",
    "\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    " \n",
    "# Path to trained weights file #transfer learning: \n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\") #we only needs its structure\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a63058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 4 #batch size\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + organoid\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 5 #one step = batch size\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf20587",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        \n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"object\", 1, \"nucleus\")\n",
    "\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # We mostly care about the x and y coordinates of each region #annotation of train folder\n",
    "        if subset == 'train':\n",
    "            annotations1 = json.load(open('dataset\\\\nucleus_jpg\\\\train\\\\via_region_data.json'))\n",
    "        elif subset == 'val':\n",
    "            annotations1 = json.load(open('dataset\\\\nucleus_jpg\\\\val\\\\via_region_data.json'))\n",
    "        else:\n",
    "            print(\"invalid subset\")\n",
    "        # print(annotations1)\n",
    "        annotations = list(annotations1.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        '''\n",
    "        print(\"check**********************************************************\")\n",
    "        for ann in annotations:\n",
    "            print(\"ann type: \", type(ann))\n",
    "            print(\"ann val: \", ann)\n",
    "            print(\"************************************\")\n",
    "        print(\"checkEnd*******************************************************\")\n",
    "        '''\n",
    "        \n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "        \n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            '''\n",
    "            print(\"check**********************************************************\")\n",
    "            print(\"a: \" , a)\n",
    "            \n",
    "            for r in a['regions']:\n",
    "                print(\"------------\")\n",
    "                print(\"a[regions] type: \", type(a['regions']))\n",
    "                print(\"a[regions]: \", a['regions'])\n",
    "                \n",
    "                print(\"------------\")\n",
    "                print(\"a[regions][r]: \", a['regions'][r])\n",
    "                \n",
    "                print(\"a[regions][r]['shape_attributes']: \", a['regions'][r]['shape_attributes'])\n",
    "                \n",
    "                #print(\"------------\")\n",
    "                #print(\"r['0'] type: \", type(r[0]) )\n",
    "                #print(\"r['0'] val: \", r[0])\n",
    "                \n",
    "                #print(\"------------\")\n",
    "                print(\"************************************\")\n",
    "            print(\"checkEnd*******************************************************\")\n",
    "            '''\n",
    "            \n",
    "            # print(a)\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. There are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #polygons = [a['regions'][r]['shape_attributes'] for r in a['regions']]\n",
    "            \n",
    "            polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "            \n",
    "            #objects = [a['regions'][s]['region_attributes']['label'] for s in a['regions']]\n",
    "            \n",
    "            objects = [s['region_attributes']['type'] for s in a['regions']]\n",
    "            \n",
    "            #print(\"objects:\",objects)\n",
    "            \n",
    "            \n",
    "            name_dict = {\"nucleus\": 1}\n",
    "            \n",
    "            # key = tuple(name_dict)\n",
    "            num_ids = [name_dict[a] for a in objects]\n",
    "     \n",
    "            # num_ids = [int(n['Event']) for n in objects]\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            print(\"numids\",num_ids)\n",
    "    \n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            #print(\"check***************************************\")\n",
    "            #print(\"a[filename]: \", a['filename'])\n",
    "            #print(\"checkEnd***********************************\")\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "\n",
    "        \tmask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6690fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(\"dataset\", \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(\"dataset\", \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    \n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the head layers\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=60,\n",
    "                layers='heads')\n",
    "    \n",
    "\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "    utils.download_trained_weights(weights_path)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf2fff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_history = model.keras_model.history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b46c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a083c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = []\n",
    "for i in range(60):\n",
    "    EPOCHS.append(i+1)\n",
    "    \n",
    "\n",
    "history = new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = [1:]\n",
    "history = new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b468d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(EPOCHS[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(EPOCHS[-1])\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(epochs, history['loss'], label=\"train loss\")\n",
    "plt.plot(epochs, history['val_loss'], label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\n",
    "plt.legend()\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
